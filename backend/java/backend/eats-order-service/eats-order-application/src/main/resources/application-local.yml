server:
  port: 8074

logging:
  level:
    org.apache.kafka: ERROR
    org.springframework.kafka: ERROR
    kafka: ERROR
    state.change.logger: ERROR

spring:
  application:
    name: eats-order-application

  jpa:
    hibernate.ddl-auto: none
    show-sql: false
    properties:
      hibernate:
        format_sql: true
  database-platform: org.hibernate.spatial.dialect.postgis.PostgisDialect

  datasource:
    url: jdbc:postgresql://localhost:5434/postgres?currentSchema=order&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
    username: postgres
    password: admin
    driver-class-name: org.postgresql.Driver
  sql:
    init:
      platform: postgres
      schema-locations: classpath:orders/init-schema.sql
      data-locations: classpath:orders/init-data.sql
      mode: always
  h2:
    console:
      enabled: true
  data:
    redis-server: redis://localhost:6379

  cloud:
    function:
      definition: restaurantApprovalInput;restaurantApprovalOutput
    stream:
      default:
        producer:
          useNativeEncoding: true
      bindings:
        restaurantApprovalProcessor-in-0:
          destination: restaurant-approval-response-topic
          group: restaurant-approval-group
        restaurantApprovalProcessor-out-0:
          destination: restaurant-notification
      kafka:
        binder:
          consumer-properties:
            "value.deserializer": io.confluent.kafka.serializers.KafkaAvroDeserializer
            "key.deserializer": org.apache.kafka.common.serialization.StringDeserializer
            "auto.offset.reset": "earliest" #TODO seek offset 사용해서 최근 n 개 부터 가져오기.
          producer-properties:
            "value.serializer": io.confluent.kafka.serializers.KafkaAvroDeserializer
            "key.serializer": org.apache.kafka.common.serialization.StringSerializer
        bindings:
          restaurantApprovalProcessor-in-0:
            consumer:
              autoCommitOffset: false
              configuration:
                isolation.level: read_committed
          restaurantApprovalProcessor-out-0:
            producer:
              recordMetadataChannel: restaurantApprovalResults

retry-config:
  initial-interval-ms: 1000
  max-interval-ms: 10000
  multiplier: 2.0
  maxAttempts: 3
  sleep-time-ms: 2000

management:
  endpoints:
    web:
      exposure:
        include: "*" # health, info, ...
  health:
    readiness-state:
      enabled: true
    liveness-state:
      enabled: true
  endpoint:
    shutdown:
      enabled: true
    heath:
      probes:
        enabled: true
  info:
    env:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name}
#
eureka:
  instance:
    preferIpAddress: true
  client:
    fetchRegistry: true
    registerWithEureka: true
    serviceUrl:
      defaultZone: http://localhost:8761/eureka/


topic-names:
  payment-request-topic-name: payment-request
  payment-response-topic-name: payment-response
  restaurant-approval-request-topic-name: restaurant-approval-request
  restaurant-approval-response-topic-name: restaurant-approval-response

kafka-config:
  # 띄어쓰기 ㄴㄴ. localhost:19092 대신 kafka-broker-1:9092 (같은 네트워크라서 그런듯)
  bootstrap-servers: localhost:19092,localhost:29092,localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  topic-names-to-create:
    - debezium.payment-request
    - debezium.payment-response
    - debezium.restaurant-approval-request
    - debezium.restaurant-approval-response
  num-of-partitions: 3
  replication-factor: 3

kafka-producer-config:
  key-serializer-class: org.apache.kafka.common.serialization.StringSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  compression-type: snappy
  acks: all
  batch-size: 16384
  batch-size-boost-factor: 100
  linger-ms: 5
  request-timeout-ms: 60000
  retry-count: 5
  driver-matching-notification-transaction-id: tx-driver-matching-notification-transaction-id
  order-approved-notification-transaction-id: tx-order-approved-notification-transaction-id

kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  auto-offset-reset: earliest
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  batch-listener: true
  auto-startup: false
  concurrency-level: 3
  session-timeout-ms: 10000
  heartbeat-interval-ms: 3000
  max-poll-interval-ms: 300000
  max-poll-records: 500
  max-partition-fetch-bytes-default: 1048576
  max-partition-fetch-bytes-boost-factor: 1
  poll-timeout-ms: 150
  enable-auto-commit: true
kafka-consumer-group-id:
  payment-consumer-group-id: debezium.payment-topic-consumer-group-id
  restaurant-approval-response-consumer-group-id: debezium.driver-approval-topic-consumer-group-id


user:
  service:
    url: "http://localhost:8077/api/info" # TODO http://user:8077 ?
  restaurant-info:
    url: "http://localhost:8077/api/restaurant"

this-service:
  outbox-scheduler-fixed-rate-ms: 1000
  outbox-scheduler-initial-delay-ms: 1000

feign-client:
  user-service:
    url: "http://localhost:8077"

feign:
  client:
    config:
      default:
        connectTimeout: 5000  # 연결 타임아웃 (밀리초)
        readTimeout: 5000     # 읽기 타임아웃 (밀리초)